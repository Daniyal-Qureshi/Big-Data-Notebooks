{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Feature Engineering\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = spark.read.csv(\"sales\",inferSchema=True, header=True).where('Description is not null')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|2010-12-01 08:26:00|     2.75|   17850.0|United Kingdom|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|   536365|    22752|SET 7 BABUSHKA NE...|       2|2010-12-01 08:26:00|     7.65|   17850.0|United Kingdom|\n",
      "|   536365|    21730|GLASS STAR FROSTE...|       6|2010-12-01 08:26:00|     4.25|   17850.0|United Kingdom|\n",
      "|   536366|    22633|HAND WARMER UNION...|       6|2010-12-01 08:28:00|     1.85|   17850.0|United Kingdom|\n",
      "|   536366|    22632|HAND WARMER RED P...|       6|2010-12-01 08:28:00|     1.85|   17850.0|United Kingdom|\n",
      "|   536367|    84879|ASSORTED COLOUR B...|      32|2010-12-01 08:34:00|     1.69|   13047.0|United Kingdom|\n",
      "|   536367|    22745|POPPY'S PLAYHOUSE...|       6|2010-12-01 08:34:00|      2.1|   13047.0|United Kingdom|\n",
      "|   536367|    22748|POPPY'S PLAYHOUSE...|       6|2010-12-01 08:34:00|      2.1|   13047.0|United Kingdom|\n",
      "|   536367|    22749|FELTCRAFT PRINCES...|       8|2010-12-01 08:34:00|     3.75|   13047.0|United Kingdom|\n",
      "|   536367|    22310|IVORY KNITTED MUG...|       6|2010-12-01 08:34:00|     1.65|   13047.0|United Kingdom|\n",
      "|   536367|    84969|BOX OF 6 ASSORTED...|       6|2010-12-01 08:34:00|     4.25|   13047.0|United Kingdom|\n",
      "|   536367|    22623|BOX OF VINTAGE JI...|       3|2010-12-01 08:34:00|     4.95|   13047.0|United Kingdom|\n",
      "|   536367|    22622|BOX OF VINTAGE AL...|       2|2010-12-01 08:34:00|     9.95|   13047.0|United Kingdom|\n",
      "|   536367|    21754|HOME BUILDING BLO...|       3|2010-12-01 08:34:00|     5.95|   13047.0|United Kingdom|\n",
      "|   536367|    21755|LOVE BUILDING BLO...|       3|2010-12-01 08:34:00|     5.95|   13047.0|United Kingdom|\n",
      "|   536367|    21777|RECIPE BOX WITH M...|       4|2010-12-01 08:34:00|     7.95|   13047.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description                        |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+-----------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|536365   |85123A   |WHITE HANGING HEART T-LIGHT HOLDER |6       |2010-12-01 08:26:00|2.55     |17850.0   |United Kingdom|\n",
      "|536365   |71053    |WHITE METAL LANTERN                |6       |2010-12-01 08:26:00|3.39     |17850.0   |United Kingdom|\n",
      "|536365   |84406B   |CREAM CUPID HEARTS COAT HANGER     |8       |2010-12-01 08:26:00|2.75     |17850.0   |United Kingdom|\n",
      "|536365   |84029G   |KNITTED UNION FLAG HOT WATER BOTTLE|6       |2010-12-01 08:26:00|3.39     |17850.0   |United Kingdom|\n",
      "|536365   |84029E   |RED WOOLLY HOTTIE WHITE HEART.     |6       |2010-12-01 08:26:00|3.39     |17850.0   |United Kingdom|\n",
      "|536365   |22752    |SET 7 BABUSHKA NESTING BOXES       |2       |2010-12-01 08:26:00|7.65     |17850.0   |United Kingdom|\n",
      "|536365   |21730    |GLASS STAR FROSTED T-LIGHT HOLDER  |6       |2010-12-01 08:26:00|4.25     |17850.0   |United Kingdom|\n",
      "|536366   |22633    |HAND WARMER UNION JACK             |6       |2010-12-01 08:28:00|1.85     |17850.0   |United Kingdom|\n",
      "|536366   |22632    |HAND WARMER RED POLKA DOT          |6       |2010-12-01 08:28:00|1.85     |17850.0   |United Kingdom|\n",
      "|536367   |84879    |ASSORTED COLOUR BIRD ORNAMENT      |32      |2010-12-01 08:34:00|1.69     |13047.0   |United Kingdom|\n",
      "|536367   |22745    |POPPY'S PLAYHOUSE BEDROOM          |6       |2010-12-01 08:34:00|2.1      |13047.0   |United Kingdom|\n",
      "|536367   |22748    |POPPY'S PLAYHOUSE KITCHEN          |6       |2010-12-01 08:34:00|2.1      |13047.0   |United Kingdom|\n",
      "|536367   |22749    |FELTCRAFT PRINCESS CHARLOTTE DOLL  |8       |2010-12-01 08:34:00|3.75     |13047.0   |United Kingdom|\n",
      "|536367   |22310    |IVORY KNITTED MUG COSY             |6       |2010-12-01 08:34:00|1.65     |13047.0   |United Kingdom|\n",
      "|536367   |84969    |BOX OF 6 ASSORTED COLOUR TEASPOONS |6       |2010-12-01 08:34:00|4.25     |13047.0   |United Kingdom|\n",
      "|536367   |22623    |BOX OF VINTAGE JIGSAW BLOCKS       |3       |2010-12-01 08:34:00|4.95     |13047.0   |United Kingdom|\n",
      "|536367   |22622    |BOX OF VINTAGE ALPHABET BLOCKS     |2       |2010-12-01 08:34:00|9.95     |13047.0   |United Kingdom|\n",
      "|536367   |21754    |HOME BUILDING BLOCK WORD           |3       |2010-12-01 08:34:00|5.95     |13047.0   |United Kingdom|\n",
      "|536367   |21755    |LOVE BUILDING BLOCK WORD           |3       |2010-12-01 08:34:00|5.95     |13047.0   |United Kingdom|\n",
      "|536367   |21777    |RECIPE BOX WITH METAL HEART        |4       |2010-12-01 08:34:00|7.95     |13047.0   |United Kingdom|\n",
      "+---------+---------+-----------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "intDF = spark.read.parquet(\"simple-ml-integers/*.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+\n",
      "|int1|int2|int3|\n",
      "+----+----+----+\n",
      "|   1|   2|   3|\n",
      "|   4|   5|   6|\n",
      "|   7|   8|   9|\n",
      "+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "intDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleDF= spark.read.parquet(\"simple-ml-scaling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------+\n",
      "| id|      features|\n",
      "+---+--------------+\n",
      "|  0|[1.0,0.1,-1.0]|\n",
      "|  1| [2.0,1.1,1.0]|\n",
      "|  0|[1.0,0.1,-1.0]|\n",
      "|  1| [2.0,1.1,1.0]|\n",
      "|  1|[3.0,10.1,3.0]|\n",
      "+---+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaleDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpleDF = spark.read.json(\"simple-ml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+------------------+\n",
      "|color| lab|value1|            value2|\n",
      "+-----+----+------+------------------+\n",
      "|green|good|     1|14.386294994851129|\n",
      "| blue| bad|     8|14.386294994851129|\n",
      "| blue| bad|    12|14.386294994851129|\n",
      "|green|good|    15| 38.97187133755819|\n",
      "|green|good|    12|14.386294994851129|\n",
      "+-----+----+------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simpleDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[InvoiceNo: string, StockCode: string, Description: string, Quantity: int, InvoiceDate: timestamp, UnitPrice: double, CustomerID: double, Country: string]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main concepts in Spark Pipelines\n",
    "\n",
    "DataFrame: Spark ML uses DataFrame from Spark SQL as an ML dataset, which can hold a variety of data types. E.g., a DataFrame could have different columns storing text, feature vectors, true labels, and predictions.\n",
    "\n",
    "Transformer: A Transformer is an algorithm which can transform one DataFrame into another DataFrame. E.g., an ML model is a Transformer which transforms DataFrame with features into a DataFrame with predictions.\n",
    "\n",
    "Estimator: An Estimator is an algorithm which can be fit on a DataFrame to produce a Transformer. E.g., a learning algorithm is an Estimator which trains on a DataFrame and produces a model.\n",
    "\n",
    "Pipeline: A Pipeline chains multiple Transformers and Estimators together to specify an ML workflow.\n",
    "\n",
    "Parameter: All Transformers and Estimators now share a common API for specifying parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Transformers\n",
    "- functions that convert raw data in some way\n",
    "- create a new interaction variable (from two other variables), to normalize a column, or to simply turn it into a Double to be input into a model\n",
    "- primarily used in preprocessing or feature generation\n",
    "- For Example - A tokenizer\n",
    "\n",
    "https://spark.apache.org/docs/latest/ml-guide.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = Tokenizer(inputCol=\"Description\", outputCol=\"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizedDF = tokens.transform(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+\n",
      "|words                                     |\n",
      "+------------------------------------------+\n",
      "|[white, hanging, heart, t-light, holder]  |\n",
      "|[white, metal, lantern]                   |\n",
      "|[cream, cupid, hearts, coat, hanger]      |\n",
      "|[knitted, union, flag, hot, water, bottle]|\n",
      "|[red, woolly, hottie, white, heart.]      |\n",
      "+------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizedDF.select('words').show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimators for Preprocessing\n",
    "\n",
    "abstracts the concept of a learning algorithm or any algorithm that fits or trains on data. Technically, an Estimator implements a method fit(), which accepts a DataFrame and produces a Model, which is a Transformer. For example, a learning algorithm such as LogisticRegression is an Estimator, and calling fit() trains a LogisticRegressionModel, which is a Model and hence a Transformer. \n",
    "- An example of this type of estimator is the StandardScaler, which scales your input column according to the range of values in that column to have a zero mean and a variance of 1 in each dimension\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## converting words into vector of features\n",
    "\n",
    "https://towardsdatascience.com/countvectorizer-hashingtf-e66f169e2d4e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "\n",
    "tf = HashingTF(inputCol='words', outputCol='rawFeatures', numFeatures=2000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuredDF = tf.transform(tokenizedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+\n",
      "|rawFeatures                                                 |\n",
      "+------------------------------------------------------------+\n",
      "|(2000,[77,152,538,1160,1348],[1.0,1.0,1.0,1.0,1.0])         |\n",
      "|(2000,[77,729,1495],[1.0,1.0,1.0])                          |\n",
      "|(2000,[127,446,477,1467,1514],[1.0,1.0,1.0,1.0,1.0])        |\n",
      "|(2000,[69,231,411,1138,1194,1932],[1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|(2000,[77,291,756,872,1142],[1.0,1.0,1.0,1.0,1.0])          |\n",
      "+------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featuredDF.select('rawFeatures').show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "\n",
    "idf = idf.fit(featuredDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfDF = idf.transform(featuredDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "|rawFeatures                               |features                                                                                                           |\n",
      "+------------------------------------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "|(20,[0,8,12,17,18],[1.0,1.0,1.0,1.0,1.0]) |(20,[0,8,12,17,18],[1.5751975729379886,1.9299098077088723,1.2214739346338364,1.902283741433941,1.5883816795301255])|\n",
      "|(20,[9,15,17],[1.0,1.0,1.0])              |(20,[9,15,17],[1.2136882300887148,1.5602476682433286,1.902283741433941])                                           |\n",
      "|(20,[6,7,14,17],[1.0,2.0,1.0,1.0])        |(20,[6,7,14,17],[1.3245382380313124,3.9147213116866175,1.740764403095775,1.902283741433941])                       |\n",
      "|(20,[9,11,12,14,18],[1.0,2.0,1.0,1.0,1.0])|(20,[9,11,12,14,18],[1.2136882300887148,2.299269087235526,1.2214739346338364,1.740764403095775,1.5883816795301255])|\n",
      "|(20,[2,11,12,16,17],[1.0,1.0,1.0,1.0,1.0])|(20,[2,11,12,16,17],[1.952573667286084,1.149634543617763,1.2214739346338364,1.6221230719614161,1.902283741433941]) |\n",
      "+------------------------------------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idfDF.select('rawFeatures', 'features').show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VectorAssembler\n",
    "\n",
    "VectorAssembler is a transformer that combines a given list of columns into a single vector column. It is useful for combining raw features and features generated by different feature transformers into a single feature vector, in order to train ML models like logistic regression and decision trees. VectorAssembler accepts the following input column types: all numeric types, boolean type, and vector type. In each row, the values of the input columns will be concatenated into a vector in the specified order.\n",
    "\n",
    "Examples\n",
    "\n",
    "Assume that we have a DataFrame with the columns id, hour, mobile, userFeatures, and clicked:\n",
    "\n",
    " id | hour | mobile | userFeatures     | clicked\n",
    "----|------|--------|------------------|---------\n",
    " 0  | 18   | 1.0    | [0.0, 10.0, 0.5] | 1.0\n",
    "userFeatures is a vector column that contains three user features. We want to combine hour, mobile, and userFeatures into a single feature vector called features and use it to predict clicked or not. If we set VectorAssembler’s input columns to hour, mobile, and userFeatures and output column to features, after transformation we should get the following DataFrame:\n",
    "\n",
    " id | hour | mobile | userFeatures     | clicked | features\n",
    "----|------|--------|------------------|---------|-----------------------------\n",
    " 0  | 18   | 1.0    | [0.0, 10.0, 0.5] | 1.0     | [18.0, 1.0, 0.0, 10.0, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+\n",
      "|int1|int2|int3|\n",
      "+----+----+----+\n",
      "|   1|   2|   3|\n",
      "|   4|   5|   6|\n",
      "|   7|   8|   9|\n",
      "+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "intDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "va = VectorAssembler(inputCols=['int1','int2','int3'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaDF = va.transform(intDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+-------------+\n",
      "|int1|int2|int3|     features|\n",
      "+----+----+----+-------------+\n",
      "|   1|   2|   3|[1.0,2.0,3.0]|\n",
      "|   4|   5|   6|[4.0,5.0,6.0]|\n",
      "|   7|   8|   9|[7.0,8.0,9.0]|\n",
      "+----+----+----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vaDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard Scaler\n",
    "\n",
    "\n",
    "\n",
    "StandardScaler transforms a dataset of Vector rows, normalizing each feature to have unit standard deviation and/or zero mean. It takes parameters:\n",
    "\n",
    "withStd: True by default. Scales the data to unit standard deviation.\n",
    "\n",
    "withMean: False by default. Centers the data with mean before scaling. It will build a dense output, so take care when applying to sparse input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler(inputCol='features', outputCol='scaledfeatures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaledModel = ss.fit(idfDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaledDF = scaledModel.transform(idfDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "|features                                                                                                           |scaledfeatures                                                                                                     |\n",
      "+-------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "|(20,[0,8,12,17,18],[1.5751975729379886,1.9299098077088723,1.2214739346338364,1.902283741433941,1.5883816795301255])|(20,[0,8,12,17,18],[2.153758333544012,2.6720472712954866,1.9545207179560422,2.5591640657380412,2.2217718354023432])|\n",
      "|(20,[9,15,17],[1.2136882300887148,1.5602476682433286,1.902283741433941])                                           |(20,[9,15,17],[1.821014888255523,2.0624598365348445,2.5591640657380412])                                           |\n",
      "+-------------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaledDF.select('features','scaledfeatures').show(2,truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFormula\n",
    "RFormula selects columns specified by an R model formula. Currently we support a limited subset of the R operators, including ‘~’, ‘.’, ‘:’, ‘+’, and ‘-‘. The basic operators are:\n",
    "\n",
    "~ separate target and terms\n",
    "+ concat terms, “+ 0” means removing intercept\n",
    "- remove a term, “- 1” means removing intercept\n",
    ": interaction (multiplication for numeric values, or binarized categorical values)\n",
    ". all columns except target\n",
    "Suppose a and b are double columns, we use the following simple examples to illustrate the effect of RFormula:\n",
    "\n",
    "y ~ a + b means model y ~ w0 + w1 * a + w2 * b where w0 is the intercept and w1, w2 are coefficients.\n",
    "y ~ a + b + a:b - 1 means model y ~ w1 * a + w2 * b + w3 * a * b where w1, w2, w3 are coefficients.\n",
    "RFormula produces a vector column of features and a double or string column of label. Like when formulas are used in R for linear regression, numeric columns will be cast to doubles. As to string input columns, they will first be transformed with StringIndexer using ordering determined by stringOrderType, and the last category after ordering is dropped, then the doubles will be one-hot encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RFormula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+------+------------------+\n",
      "|color| lab|value1|            value2|\n",
      "+-----+----+------+------------------+\n",
      "|green|good|     1|14.386294994851129|\n",
      "| blue| bad|     8|14.386294994851129|\n",
      "| blue| bad|    12|14.386294994851129|\n",
      "|green|good|    15| 38.97187133755819|\n",
      "|green|good|    12|14.386294994851129|\n",
      "|green| bad|    16|14.386294994851129|\n",
      "|  red|good|    35|14.386294994851129|\n",
      "|  red| bad|     1| 38.97187133755819|\n",
      "|  red| bad|     2|14.386294994851129|\n",
      "|  red| bad|    16|14.386294994851129|\n",
      "|  red|good|    45| 38.97187133755819|\n",
      "|green|good|     1|14.386294994851129|\n",
      "| blue| bad|     8|14.386294994851129|\n",
      "| blue| bad|    12|14.386294994851129|\n",
      "|green|good|    15| 38.97187133755819|\n",
      "|green|good|    12|14.386294994851129|\n",
      "|green| bad|    16|14.386294994851129|\n",
      "|  red|good|    35|14.386294994851129|\n",
      "|  red| bad|     1| 38.97187133755819|\n",
      "|  red| bad|     2|14.386294994851129|\n",
      "+-----+----+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simpleDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RFormula(formula='lab ~ .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfModel = rf.fit(simpleDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelDF = rfModel.transform(simpleDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+-----+\n",
      "|features                         |label|\n",
      "+---------------------------------+-----+\n",
      "|[0.0,1.0,1.0,14.386294994851129] |1.0  |\n",
      "|[0.0,0.0,8.0,14.386294994851129] |0.0  |\n",
      "|[0.0,0.0,12.0,14.386294994851129]|0.0  |\n",
      "|[0.0,1.0,15.0,38.97187133755819] |1.0  |\n",
      "|[0.0,1.0,12.0,14.386294994851129]|1.0  |\n",
      "|[0.0,1.0,16.0,14.386294994851129]|0.0  |\n",
      "|[1.0,0.0,35.0,14.386294994851129]|1.0  |\n",
      "|[1.0,0.0,1.0,38.97187133755819]  |0.0  |\n",
      "|[1.0,0.0,2.0,14.386294994851129] |0.0  |\n",
      "|[1.0,0.0,16.0,14.386294994851129]|0.0  |\n",
      "|[1.0,0.0,45.0,38.97187133755819] |1.0  |\n",
      "|[0.0,1.0,1.0,14.386294994851129] |1.0  |\n",
      "|[0.0,0.0,8.0,14.386294994851129] |0.0  |\n",
      "|[0.0,0.0,12.0,14.386294994851129]|0.0  |\n",
      "|[0.0,1.0,15.0,38.97187133755819] |1.0  |\n",
      "|[0.0,1.0,12.0,14.386294994851129]|1.0  |\n",
      "|[0.0,1.0,16.0,14.386294994851129]|0.0  |\n",
      "|[1.0,0.0,35.0,14.386294994851129]|1.0  |\n",
      "|[1.0,0.0,1.0,38.97187133755819]  |0.0  |\n",
      "|[1.0,0.0,2.0,14.386294994851129] |0.0  |\n",
      "+---------------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labelDF.select(\"features\", \"label\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [features#1660 AS features#1670, UDF(lab#194) AS label#1685]\n",
      "+- *(1) Project [lab#194, UDF(named_struct(onehot_6a4441f02305, UDF(stridx_05d5bf0425f5#1628, 0), value1_double_RFormula_0c537f2b4141, cast(value1#195L as double), value2, value2#196, interaction_7f067c050cfe, UDF(named_struct(stridx_05d5bf0425f5, stridx_05d5bf0425f5#1628, col2, cast(value1#195L as double))), interaction_626f2e09e204, UDF(named_struct(stridx_05d5bf0425f5, stridx_05d5bf0425f5#1628, value2, value2#196)))) AS features#1660]\n",
      "   +- *(1) Project [lab#194, value1#195L, value2#196, UDF(color#193) AS stridx_05d5bf0425f5#1628]\n",
      "      +- *(1) FileScan json [color#193,lab#194,value1#195L,value2#196] Batched: false, Format: JSON, Location: InMemoryFileIndex[file:/E:/BigDataAnalytics/Notebooks/Notebooks/data/simple-ml], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<color:string,lab:string,value1:bigint,value2:double>\n"
     ]
    }
   ],
   "source": [
    "labelDF.select(\"features\", \"label\").explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf1 = RFormula(formula='lab~color+value1+value2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf1DF = rf1.fit(simpleDF).transform(simpleDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------------------------+-----+\n",
      "|color|features                         |label|\n",
      "+-----+---------------------------------+-----+\n",
      "|green|[0.0,1.0,1.0,14.386294994851129] |1.0  |\n",
      "|blue |[0.0,0.0,8.0,14.386294994851129] |0.0  |\n",
      "|blue |[0.0,0.0,12.0,14.386294994851129]|0.0  |\n",
      "|green|[0.0,1.0,15.0,38.97187133755819] |1.0  |\n",
      "|green|[0.0,1.0,12.0,14.386294994851129]|1.0  |\n",
      "|green|[0.0,1.0,16.0,14.386294994851129]|0.0  |\n",
      "|red  |[1.0,0.0,35.0,14.386294994851129]|1.0  |\n",
      "|red  |[1.0,0.0,1.0,38.97187133755819]  |0.0  |\n",
      "|red  |[1.0,0.0,2.0,14.386294994851129] |0.0  |\n",
      "|red  |[1.0,0.0,16.0,14.386294994851129]|0.0  |\n",
      "|red  |[1.0,0.0,45.0,38.97187133755819] |1.0  |\n",
      "|green|[0.0,1.0,1.0,14.386294994851129] |1.0  |\n",
      "|blue |[0.0,0.0,8.0,14.386294994851129] |0.0  |\n",
      "|blue |[0.0,0.0,12.0,14.386294994851129]|0.0  |\n",
      "|green|[0.0,1.0,15.0,38.97187133755819] |1.0  |\n",
      "|green|[0.0,1.0,12.0,14.386294994851129]|1.0  |\n",
      "|green|[0.0,1.0,16.0,14.386294994851129]|0.0  |\n",
      "|red  |[1.0,0.0,35.0,14.386294994851129]|1.0  |\n",
      "|red  |[1.0,0.0,1.0,38.97187133755819]  |0.0  |\n",
      "|red  |[1.0,0.0,2.0,14.386294994851129] |0.0  |\n",
      "+-----+---------------------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf1DF.select('color','features','label').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|      features|label|\n",
      "+--------------+-----+\n",
      "|[0.0,0.0,18.0]|  1.0|\n",
      "|[0.0,1.0,12.0]|  0.0|\n",
      "|[1.0,0.0,15.0]|  0.0|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = spark.createDataFrame(\n",
    "    [(7, \"US\", 18, 1.0),\n",
    "     (8, \"CA\", 12, 0.0),\n",
    "     (9, \"NZ\", 15, 0.0)],\n",
    "    [\"id\", \"country\", \"hour\", \"clicked\"])\n",
    "\n",
    "formula = RFormula(formula=\"clicked ~   country + hour\")\n",
    "\n",
    "output = formula.fit(dataset).transform(dataset)\n",
    "output.select(\"features\", \"label\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----+-------+\n",
      "| id|country|hour|clicked|\n",
      "+---+-------+----+-------+\n",
      "|  7|     US|  18|    1.0|\n",
      "|  8|     CA|  12|    0.0|\n",
      "|  9|     NZ|  15|    0.0|\n",
      "+---+-------+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQLTransformer\n",
    "SQLTransformer implements the transformations which are defined by SQL statement. Currently, only supported SQL syntax is like \"SELECT ... FROM __THIS__ ...\" where \"__THIS__\" represents the underlying table of the input dataset. The select clause specifies the fields, constants, and expressions to display in the output, and can be any select clause that Spark SQL supports. Users can also use Spark SQL built-in function and UDFs to operate on these selected columns. For example, SQLTransformer supports statements like:\n",
    "\n",
    "SELECT a, a + b AS a_b FROM __THIS__\n",
    "\n",
    "SELECT a, SQRT(b) AS b_sqrt FROM __THIS__ where a > 5\n",
    "\n",
    "SELECT a, b, SUM(c) AS c_sum FROM __THIS__ GROUP BY a, b\n",
    "\n",
    "Examples\n",
    "\n",
    "Assume that we have the following DataFrame with columns id, v1 and v2:\n",
    "\n",
    " id |  v1 |  v2\n",
    "----|-----|-----\n",
    " 0  | 1.0 | 3.0  \n",
    " 2  | 2.0 | 5.0\n",
    "This is the output of the SQLTransformer with statement \"SELECT *, (v1 + v2) AS v3, (v1 * v2) AS v4 FROM __THIS__\":\n",
    "\n",
    " id |  v1 |  v2 |  v3 |  v4\n",
    "----|-----|-----|-----|-----\n",
    " 0  | 1.0 | 3.0 | 4.0 | 3.0\n",
    " 2  | 2.0 | 5.0 | 7.0 |10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [id#1232L, v1#1233, v2#1234, (v1#1233 + v2#1234) AS v3#1254, (v1#1233 * v2#1234) AS v4#1255]\n",
      "+- Scan ExistingRDD[id#1232L,v1#1233,v2#1234]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import SQLTransformer\n",
    "\n",
    "df = spark.createDataFrame([\n",
    "    (0, 1.0, 3.0),\n",
    "    (2, 2.0, 5.0)\n",
    "], [\"id\", \"v1\", \"v2\"])\n",
    "sqlTrans = SQLTransformer(\n",
    "    statement=\"SELECT *, (v1 + v2) AS v3, (v1 * v2) AS v4 FROM __THIS__\")\n",
    "sqlTrans.transform(df).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlDF = sqlTrans.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+----+\n",
      "| id| v1| v2| v3|  v4|\n",
      "+---+---+---+---+----+\n",
      "|  0|1.0|3.0|4.0| 3.0|\n",
      "|  2|2.0|5.0|7.0|10.0|\n",
      "+---+---+---+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Continuous Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bucketing\n",
    "When specifying your\n",
    "bucket points, the values you pass into splits must satisfy three requirements:\n",
    "- The minimum value in your splits array must be less than the minimum value in your DataFrame.\n",
    "- The maximum value in your splits array must be greater than the maximum value in your DataFrame.\n",
    "- You need to specify at a minimum three values in the splits array, which creates two buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quatiles = sales.approxQuantile('unitprice',[0.2,0.4,0.6,0.8,1.0],0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.25, 1.95, 2.95, 4.95, 887.52]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quatiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "quatiles.insert(0,-float(\"inf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "quatiles.insert(6,float(\"inf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-inf, 1.25, 1.95, 2.95, 4.95, 887.52, inf]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quatiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Bucketizer\n",
    "\n",
    "b = Bucketizer(splits=quatiles,inputCol='UnitPrice',outputCol='buck_unitprice')\n",
    "\n",
    "bucketedDF = b.transform(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+\n",
      "|unitprice|buck_unitprice|\n",
      "+---------+--------------+\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.72|           0.0|\n",
      "|     0.95|           0.0|\n",
      "|     0.99|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.84|           0.0|\n",
      "|     0.95|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.43|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.95|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.43|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.43|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.24|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.84|           0.0|\n",
      "|     0.64|           0.0|\n",
      "|     0.43|           0.0|\n",
      "|     0.95|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.95|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.95|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.72|           0.0|\n",
      "|     0.64|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.43|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.81|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.21|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.43|           0.0|\n",
      "|     0.43|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.72|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.43|           0.0|\n",
      "|     0.43|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.72|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.72|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.32|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.21|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.21|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.43|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.81|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.38|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.21|           0.0|\n",
      "|     0.12|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.43|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.81|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.95|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|      0.1|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.43|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.84|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.72|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.12|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     1.05|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.43|           0.0|\n",
      "|     0.43|           0.0|\n",
      "|     0.43|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.19|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|      0.0|           0.0|\n",
      "|      0.0|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.03|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.95|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.95|           0.0|\n",
      "|     0.75|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.36|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.36|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.36|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.36|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.36|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.34|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.34|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.34|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.72|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.16|           0.0|\n",
      "|     0.43|           0.0|\n",
      "|     0.32|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.72|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.36|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.36|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.36|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.72|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.36|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.36|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.36|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.36|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.34|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.34|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.72|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.16|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.12|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.43|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.64|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.95|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.21|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.64|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.75|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.72|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.72|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.72|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.72|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.12|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.21|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.95|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.72|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.18|           0.0|\n",
      "|     0.43|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.43|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.75|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.19|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.21|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.84|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.21|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.95|           0.0|\n",
      "|     0.19|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.95|           0.0|\n",
      "|     0.95|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.55|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     1.06|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|      0.0|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.29|           0.0|\n",
      "|     0.65|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.85|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.42|           0.0|\n",
      "|     0.85|           0.0|\n",
      "+---------+--------------+\n",
      "only showing top 1000 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bucketedDF.select('unitprice','buck_unitprice').sort('buck_unitprice').show(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is to split based on percentiles\n",
    "in our data. This is done with QuantileDiscretizer, which will bucket the values into userspecified buckets with the splits being determined by approximate quantiles values. For instance,\n",
    "the 90th quantile is the point in your data at which 90% of the data is below that value. You can\n",
    "control how finely the buckets should be split by setting the relative error for the approximate\n",
    "quantiles calculation using setRelativeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import QuantileDiscretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckDF = QuantileDiscretizer(numBuckets=5,inputCol='UnitPrice',outputCol='buck_unit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckMod = buckDF.fit(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-inf, 1.25, 1.95, 2.95, 5.06, inf]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buckMod.getSplits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckDF = buckMod.transform(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|unitprice|buck_unit|\n",
      "+---------+---------+\n",
      "|     0.85|      0.0|\n",
      "|     0.42|      0.0|\n",
      "|     0.55|      0.0|\n",
      "|     1.06|      0.0|\n",
      "|     1.06|      0.0|\n",
      "|     0.85|      0.0|\n",
      "|     1.06|      0.0|\n",
      "|     1.06|      0.0|\n",
      "|     1.06|      0.0|\n",
      "|     1.06|      0.0|\n",
      "|     1.06|      0.0|\n",
      "|     0.85|      0.0|\n",
      "|     0.42|      0.0|\n",
      "|     0.85|      0.0|\n",
      "|     0.42|      0.0|\n",
      "|     0.85|      0.0|\n",
      "|     0.85|      0.0|\n",
      "|     1.06|      0.0|\n",
      "|     0.42|      0.0|\n",
      "|     1.06|      0.0|\n",
      "+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "buckDF.select('unitprice','buck_unit').sort('buck_unit').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling and Normalization\n",
    "\n",
    "StandardScaler  --> already covered\n",
    "\n",
    "MinMaxScaler\n",
    "\n",
    "The MinMaxScaler will scale the values in a vector (component wise) to the proportional values on a scale from a given min value to a max value. If you specify the minimum value to be 0 and the maximum value to be 1, then all the values will fall in between 0 and 1:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import MinMaxScaler\n",
    "\n",
    "mmscale = MinMaxScaler(min=0,max=1,inputCol='features',outputCol='scaledfeatures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmscaleMod = mmscale.fit(labelDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmDF = mmscaleMod.transform(labelDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------+\n",
      "|scaledfeatures                                                                                 |\n",
      "+-----------------------------------------------------------------------------------------------+\n",
      "|[0.0,1.0,0.0,0.0,0.0,0.0,0.0625,0.0,0.0,0.36914560428066195,0.0]                               |\n",
      "|[0.0,0.0,1.0,0.1590909090909091,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,1.0]                    |\n",
      "|[0.0,0.0,1.0,0.25,0.0,0.0,0.0,1.0,0.0,0.0,1.0]                                                 |\n",
      "|[0.0,1.0,0.0,0.3181818181818182,1.0,0.0,0.9375,0.0,0.0,1.0,0.0]                                |\n",
      "|[0.0,1.0,0.0,0.25,0.0,0.0,0.75,0.0,0.0,0.36914560428066195,0.0]                                |\n",
      "|[0.0,1.0,0.0,0.3409090909090909,0.0,0.0,1.0,0.0,0.0,0.36914560428066195,0.0]                   |\n",
      "|[1.0,0.0,0.0,0.7727272727272727,0.0,0.7777777777777778,0.0,0.0,0.36914560428066195,0.0,0.0]    |\n",
      "|[1.0,0.0,0.0,0.0,1.0,0.022222222222222223,0.0,0.0,1.0,0.0,0.0]                                 |\n",
      "|[1.0,0.0,0.0,0.022727272727272728,0.0,0.044444444444444446,0.0,0.0,0.36914560428066195,0.0,0.0]|\n",
      "|[1.0,0.0,0.0,0.3409090909090909,0.0,0.35555555555555557,0.0,0.0,0.36914560428066195,0.0,0.0]   |\n",
      "|[1.0,0.0,0.0,1.0,1.0,1.0,0.0,0.0,1.0,0.0,0.0]                                                  |\n",
      "|[0.0,1.0,0.0,0.0,0.0,0.0,0.0625,0.0,0.0,0.36914560428066195,0.0]                               |\n",
      "|[0.0,0.0,1.0,0.1590909090909091,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,1.0]                    |\n",
      "|[0.0,0.0,1.0,0.25,0.0,0.0,0.0,1.0,0.0,0.0,1.0]                                                 |\n",
      "|[0.0,1.0,0.0,0.3181818181818182,1.0,0.0,0.9375,0.0,0.0,1.0,0.0]                                |\n",
      "|[0.0,1.0,0.0,0.25,0.0,0.0,0.75,0.0,0.0,0.36914560428066195,0.0]                                |\n",
      "|[0.0,1.0,0.0,0.3409090909090909,0.0,0.0,1.0,0.0,0.0,0.36914560428066195,0.0]                   |\n",
      "|[1.0,0.0,0.0,0.7727272727272727,0.0,0.7777777777777778,0.0,0.0,0.36914560428066195,0.0,0.0]    |\n",
      "|[1.0,0.0,0.0,0.0,1.0,0.022222222222222223,0.0,0.0,1.0,0.0,0.0]                                 |\n",
      "|[1.0,0.0,0.0,0.022727272727272728,0.0,0.044444444444444446,0.0,0.0,0.36914560428066195,0.0,0.0]|\n",
      "+-----------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mmDF.select('scaledfeatures').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmscale = MinMaxScaler(min=0,max=1,inputCol='rawFeatures',outputCol='scaledfeatures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmMod = mmscale.fit(featuredDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmDF1 = mmMod.transform(featuredDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|scaledfeatures                                                                                                                                |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.25,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0]|\n",
      "|[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0]                |\n",
      "|[0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.3333333333333333,0.0,0.0]                               |\n",
      "|[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.5,0.25,0.0,0.5,0.0,0.0,0.0,0.3333333333333333,0.0]                              |\n",
      "|[0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.25,0.25,0.0,0.0,0.0,0.5,0.3333333333333333,0.0,0.0]                             |\n",
      "|[0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6666666666666666,0.0,0.0,0.5,0.0,0.0,0.0]                |\n",
      "|[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.3333333333333333,0.0,0.25,0.0,0.0,0.0,0.5,0.0,0.3333333333333333,0.0]               |\n",
      "|[0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.3333333333333333,0.0,0.0]                               |\n",
      "|[0.6666666666666666,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.25,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0]               |\n",
      "|[0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.3333333333333333,0.0,0.0,0.0,0.0]                               |\n",
      "|[0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]                                              |\n",
      "|[0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]                                              |\n",
      "|[0.0,0.0,0.0,0.0,0.0,0.5,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.25,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0]                              |\n",
      "|[0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.25,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]               |\n",
      "|[0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.25,0.0,0.5,0.3333333333333333,0.0,0.0,0.0,0.0]|\n",
      "|[0.3333333333333333,0.0,0.3333333333333333,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.25,0.0,0.0,0.0,0.0,0.0,0.0,0.0]|\n",
      "|[0.3333333333333333,0.0,0.0,0.6666666666666666,0.0,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.0,0.25,0.0,0.0,0.0,0.0,0.0,0.0,0.0]               |\n",
      "|[0.0,0.0,0.0,0.0,0.0,0.5,0.0,0.0,0.0,0.0,0.0,0.25,0.25,0.0,0.0,0.0,0.0,0.0,0.0,0.5]                                                           |\n",
      "|[0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.25,0.25,0.0,0.0,0.0,0.0,0.0,0.0,0.5]                                            |\n",
      "|[0.3333333333333333,0.0,0.0,0.3333333333333333,0.0,0.0,0.0,0.0,0.0,0.3333333333333333,0.3333333333333333,0.0,0.25,0.0,0.0,0.0,0.0,0.0,0.0,0.0]|\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mmDF1.select('scaledfeatures').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MaxAbsScaler\n",
    "The max absolute scaler (MaxAbsScaler) scales the data by dividing each value by the maximum\n",
    "absolute value in this feature. All values therefore end up between −1 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizer\n",
    "The normalizer allows us to scale multidimensional vectors using one of several power norms,\n",
    "set through the parameter “p”. For example, we can use the Manhattan norm (or Manhattan\n",
    "distance) with p = 1, Euclidean norm with p = 2, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Normalizer\n",
    "\n",
    "nor = Normalizer(p=1,inputCol='rawFeatures',outputCol='norFeatures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "norDF = nor.transform(featuredDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------+\n",
      "|norFeatures                                                                                                              |\n",
      "+-------------------------------------------------------------------------------------------------------------------------+\n",
      "|(20,[0,8,12,17,18],[0.2,0.2,0.2,0.2,0.2])                                                                                |\n",
      "|(20,[9,15,17],[0.3333333333333333,0.3333333333333333,0.3333333333333333])                                                |\n",
      "|(20,[6,7,14,17],[0.2,0.4,0.2,0.2])                                                                                       |\n",
      "|(20,[9,11,12,14,18],[0.16666666666666666,0.3333333333333333,0.16666666666666666,0.16666666666666666,0.16666666666666666])|\n",
      "|(20,[2,11,12,16,17],[0.2,0.2,0.2,0.2,0.2])                                                                               |\n",
      "+-------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "norDF.select('norFeatures').show(5,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherDF = spark.read.parquet(\"ny/*.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+----+--------------------+-----+--------------------+\n",
      "|    Station|Measurement|Year|              Values|state|                name|\n",
      "+-----------+-----------+----+--------------------+-----+--------------------+\n",
      "|USW00094704|   PRCP_s20|1945|[00 00 00 00 00 0...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   PRCP_s20|1946|[99 46 52 46 0B 4...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   PRCP_s20|1947|[79 4C 75 4C 8F 4...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   PRCP_s20|1948|[72 48 7A 48 85 4...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   PRCP_s20|1949|[BB 49 BC 49 BD 4...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   PRCP_s20|1950|[6E 4B 93 4B BB 4...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   PRCP_s20|1951|[27 4A 32 4A 28 4...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   PRCP_s20|1952|[54 4B 60 4B 6A 4...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   PRCP_s20|1953|[48 4A 37 4A 28 4...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   PRCP_s20|2000|[DE 4A D4 4A CA 4...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   PRCP_s20|2001|[D9 44 C7 44 B6 4...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   PRCP_s20|2002|[CF 4B B8 4B A1 4...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   PRCP_s20|2003|[18 4B F1 4A D2 4...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   PRCP_s20|2004|[CE 4A 9C 4A 6B 4...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   PRCP_s20|2005|[DD 4C D3 4C C9 4...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   PRCP_s20|2006|[91 4B 9F 4B AC 4...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   PRCP_s20|2007|[39 4E 36 4E 34 4...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   PRCP_s20|2008|[3A 4A 11 4A EA 4...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   PRCP_s20|2009|[5C 4A 3F 4A 26 4...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   PRCP_s20|2010|[A1 48 97 48 8E 4...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   PRCP_s20|2011|[43 47 21 47 FE 4...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   PRCP_s20|2012|[40 4B 2A 4B 15 4...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   PRCP_s20|2013|[29 4D 1B 4D 16 4...|   NY|   DANSVILLE MUNI AP|\n",
      "|USC00307356|   TOBS_s20|1956|[00 00 00 00 00 0...|   NY|SABATTIS WHITNEY ...|\n",
      "|USC00307356|   TOBS_s20|1957|[09 D5 1A D5 27 D...|   NY|SABATTIS WHITNEY ...|\n",
      "|USC00307356|   TOBS_s20|1958|[9C D3 C6 D3 F0 D...|   NY|SABATTIS WHITNEY ...|\n",
      "|USW00094704|   TMAX_s20|1945|[00 00 00 00 00 0...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   TMAX_s20|1946|[50 4D 59 4D 67 4...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   TMAX_s20|1947|[00 55 80 54 00 7...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   TMAX_s20|1948|[07 40 13 3A 2E B...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   TMAX_s20|1949|[41 51 3B 51 37 5...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   TMAX_s20|1950|[0C 54 0D 54 0C 5...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   TMAX_s20|1951|[97 4D 9A 4D 9C 4...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   TMAX_s20|1952|[FD 4F F0 4F E0 4...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   TMAX_s20|1953|[E7 50 E2 50 D8 5...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   TMAX_s20|2000|[95 52 79 52 5C 5...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   TMAX_s20|2001|[BF 45 17 46 62 4...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   TMAX_s20|2002|[BE 52 A7 52 90 5...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   TMAX_s20|2003|[6E 43 50 41 5D 3...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   TMAX_s20|2004|[C3 4D 4F 4D DD 4...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   TMAX_s20|2005|[EF 4E 9F 4E 50 4...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   TMAX_s20|2006|[8C 51 A0 51 B6 5...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   TMAX_s20|2007|[82 53 42 53 00 5...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   TMAX_s20|2008|[A3 50 9C 50 94 5...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   TMAX_s20|2009|[B2 4A 40 4A CF 4...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   TMAX_s20|2010|[EA 49 91 49 39 4...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   TMAX_s20|2011|[17 45 2A 44 8E 4...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   TMAX_s20|2012|[31 53 14 53 F8 5...|   NY|   DANSVILLE MUNI AP|\n",
      "|USW00094704|   TMAX_s20|2013|[4C 51 27 51 09 5...|   NY|   DANSVILLE MUNI AP|\n",
      "|USC00306957|   SNWD_s20|1969|[00 00 00 00 00 0...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|1971|[73 40 31 40 E1 3...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|1972|[F3 57 09 58 1B 5...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|1973|[F6 5B FE 5B 03 5...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|1974|[55 5C 56 5C 57 5...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|1975|[CA 5C DC 5C DF 5...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|1976|[48 5F 4B 5F 4B 5...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|1977|[70 5D 88 5D 9E 5...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|1978|[AE 5D C2 5D D6 5...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|1979|[00 7E 00 7E 00 7...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|1980|[60 52 60 52 60 5...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|1981|[AB 5C AB 5C AA 5...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|1982|[00 7E 00 7E 00 7...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|1983|[00 7E 00 7E 00 7...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|1984|[00 7E 00 7E 00 7...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|1985|[00 00 00 00 00 0...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|1986|[8B 5E 8F 5E 92 5...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|1987|[00 7E 00 7E 00 7...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|1988|[00 00 00 00 00 0...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|1989|[00 7E 00 7E 00 7...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|1990|[00 7E 00 7E 00 7...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|1991|[00 00 00 00 00 0...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|1992|[00 7E 00 7E 00 7...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|1993|[FA 57 38 58 72 5...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|1994|[28 60 28 60 28 6...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|1995|[00 00 00 00 00 0...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|1996|[03 5F F2 5E E4 5...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|1997|[C0 58 C5 58 CB 5...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|1998|[FB 5B ED 5B DB 5...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|1999|[63 58 7C 58 92 5...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|2000|[00 00 00 00 00 0...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|2001|[2A 4E A4 4E 3B 4...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|2002|[00 00 00 00 00 0...|   NY|           RAY BROOK|\n",
      "|USC00306957|   SNWD_s20|2003|[00 00 00 00 00 0...|   NY|           RAY BROOK|\n",
      "|USC00308625|   TOBS_s20|1979|[00 00 00 00 00 0...|   NY|          TULLY 4 NE|\n",
      "|USC00308625|   TOBS_s20|1980|[28 CE A4 CE 2B C...|   NY|          TULLY 4 NE|\n",
      "|USC00308625|   TOBS_s20|1981|[43 D6 4A D6 4F D...|   NY|          TULLY 4 NE|\n",
      "|USC00308625|   TOBS_s20|1982|[AF D4 C9 D4 E2 D...|   NY|          TULLY 4 NE|\n",
      "|USC00308625|   TOBS_s20|1983|[C1 D1 F1 D1 1E D...|   NY|          TULLY 4 NE|\n",
      "|USC00308625|   TOBS_s20|1984|[43 D5 53 D5 62 D...|   NY|          TULLY 4 NE|\n",
      "|USC00308625|   TOBS_s20|1985|[22 D2 63 D2 9E D...|   NY|          TULLY 4 NE|\n",
      "|USC00308625|   TOBS_s20|1986|[BC D3 C9 D3 DC D...|   NY|          TULLY 4 NE|\n",
      "|USC00308625|   TOBS_s20|1987|[03 D2 2D D2 56 D...|   NY|          TULLY 4 NE|\n",
      "|USC00308625|   TOBS_s20|1988|[B8 D3 E6 D3 08 D...|   NY|          TULLY 4 NE|\n",
      "|USC00308625|   TOBS_s20|1989|[7E D2 80 D2 85 D...|   NY|          TULLY 4 NE|\n",
      "|USC00308625|   TOBS_s20|1990|[6E D4 54 D4 38 D...|   NY|          TULLY 4 NE|\n",
      "|USC00308625|   TOBS_s20|1991|[D5 D0 F8 D0 18 D...|   NY|          TULLY 4 NE|\n",
      "|USC00308625|   TOBS_s20|1992|[18 D1 43 D1 71 D...|   NY|          TULLY 4 NE|\n",
      "|USC00308625|   TOBS_s20|1993|[C6 CF 04 D0 20 D...|   NY|          TULLY 4 NE|\n",
      "|USC00308625|   TOBS_s20|1994|[F7 D5 17 D6 36 D...|   NY|          TULLY 4 NE|\n",
      "|USW00014743|   TMIN_s20|1893|[BA D5 F2 D5 28 D...|   NY|         CANTON 4 SE|\n",
      "+-----------+-----------+----+--------------------+-----+--------------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weatherDF.select('Station','Measurement','Year','Values','state','name').show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Categorical Features\n",
    "The most common task for categorical features is indexing. Indexing converts a categorical\n",
    "variable in a column to a numerical one that you can plug into machine learning algorithms.\n",
    "While this is conceptually simple, there are some catches that are important to keep in mind so\n",
    "that Spark can do this in a stable and repeatable manner.\n",
    "In general, we recommend re-indexing every categorical variable when pre-processing just for\n",
    "consistency’s sake. This can be helpful in maintaining your models over the long run as your\n",
    "encoding practices may change over time.\n",
    "\n",
    "StringIndexer\n",
    "\n",
    "The simplest way to index is via the StringIndexer, which maps strings to different numerical\n",
    "IDs. Spark’s StringIndexer also creates metadata attached to the DataFrame that specify what\n",
    "inputs correspond to what outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "str_ind_df = spark.createDataFrame(\n",
    "    [(0, \"a\"), (1, \"b\"), (2, \"c\"), (3, \"a\"), (4, \"a\"), (5, \"c\")],\n",
    "    [\"id\", \"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| id|category|\n",
      "+---+--------+\n",
      "|  0|       a|\n",
      "|  1|       b|\n",
      "|  2|       c|\n",
      "|  3|       a|\n",
      "|  4|       a|\n",
      "|  5|       c|\n",
      "+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "str_ind_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "si = StringIndexer(inputCol='category',outputCol='indexed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "siModel = si.fit(str_ind_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "siDF = siModel.transform(str_ind_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------+\n",
      "| id|category|indexed|\n",
      "+---+--------+-------+\n",
      "|  0|       a|    0.0|\n",
      "|  1|       b|    2.0|\n",
      "|  2|       c|    1.0|\n",
      "|  3|       a|    0.0|\n",
      "|  4|       a|    0.0|\n",
      "|  5|       c|    1.0|\n",
      "+---+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "siDF.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using same indexer with other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_ind_df1 = spark.createDataFrame(\n",
    "    [(0, \"a\"), (1, \"b\"), (2, \"d\"), (3, \"a\"), (4, \"a\"), (5, \"e\"),(5, \"f\"),(5, \"f\")],\n",
    "    [\"id\", \"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------+\n",
      "| id|category|indexed|\n",
      "+---+--------+-------+\n",
      "|  0|       a|    0.0|\n",
      "|  1|       b|    3.0|\n",
      "|  2|       d|    4.0|\n",
      "|  3|       a|    0.0|\n",
      "|  4|       a|    0.0|\n",
      "|  5|       e|    2.0|\n",
      "|  5|       f|    1.0|\n",
      "|  5|       f|    1.0|\n",
      "+---+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "si.fit(str_ind_df1).transform(str_ind_df1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|2010-12-01 08:26:00|     2.55|   17850.0|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|2010-12-01 08:26:00|     2.75|   17850.0|United Kingdom|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|2010-12-01 08:26:00|     3.39|   17850.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = Tokenizer(inputCol='Description',outputCol='tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkDF = tk.transform(sales.select('Description'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|         Description|              tokens|\n",
      "+--------------------+--------------------+\n",
      "|WHITE HANGING HEA...|[white, hanging, ...|\n",
      "| WHITE METAL LANTERN|[white, metal, la...|\n",
      "|CREAM CUPID HEART...|[cream, cupid, he...|\n",
      "|KNITTED UNION FLA...|[knitted, union, ...|\n",
      "|RED WOOLLY HOTTIE...|[red, woolly, hot...|\n",
      "|SET 7 BABUSHKA NE...|[set, 7, babushka...|\n",
      "|GLASS STAR FROSTE...|[glass, star, fro...|\n",
      "|HAND WARMER UNION...|[hand, warmer, un...|\n",
      "|HAND WARMER RED P...|[hand, warmer, re...|\n",
      "|ASSORTED COLOUR B...|[assorted, colour...|\n",
      "|POPPY'S PLAYHOUSE...|[poppy's, playhou...|\n",
      "|POPPY'S PLAYHOUSE...|[poppy's, playhou...|\n",
      "|FELTCRAFT PRINCES...|[feltcraft, princ...|\n",
      "|IVORY KNITTED MUG...|[ivory, knitted, ...|\n",
      "|BOX OF 6 ASSORTED...|[box, of, 6, asso...|\n",
      "|BOX OF VINTAGE JI...|[box, of, vintage...|\n",
      "|BOX OF VINTAGE AL...|[box, of, vintage...|\n",
      "|HOME BUILDING BLO...|[home, building, ...|\n",
      "|LOVE BUILDING BLO...|[love, building, ...|\n",
      "|RECIPE BOX WITH M...|[recipe, box, wit...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tkDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = HashingTF(inputCol='tokens',outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfDF = tf.transform(tkDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+---------------------------------------------------------------------------+\n",
      "|tokens                                    |features                                                                   |\n",
      "+------------------------------------------+---------------------------------------------------------------------------+\n",
      "|[white, hanging, heart, t-light, holder]  |(262144,[2618,57341,102296,121320,193684],[1.0,1.0,1.0,1.0,1.0])           |\n",
      "|[white, metal, lantern]                   |(262144,[57341,68281,240983],[1.0,1.0,1.0])                                |\n",
      "|[cream, cupid, hearts, coat, hanger]      |(262144,[1133,69598,172939,179146,255343],[1.0,1.0,1.0,1.0,1.0])           |\n",
      "|[knitted, union, flag, hot, water, bottle]|(262144,[4842,42343,61666,149851,167916,187621],[1.0,1.0,1.0,1.0,1.0,1.0]) |\n",
      "|[red, woolly, hottie, white, heart.]      |(262144,[30600,57341,81060,100086,195459],[1.0,1.0,1.0,1.0,1.0])           |\n",
      "|[set, 7, babushka, nesting, boxes]        |(262144,[77099,80112,94337,135533,203156],[1.0,1.0,1.0,1.0,1.0])           |\n",
      "|[glass, star, frosted, t-light, holder]   |(262144,[113864,121320,145718,193684,213314],[1.0,1.0,1.0,1.0,1.0])        |\n",
      "|[hand, warmer, union, jack]               |(262144,[4842,58545,154435,232367],[1.0,1.0,1.0,1.0])                      |\n",
      "|[hand, warmer, red, polka, dot]           |(262144,[58545,167356,178320,195459,232367],[1.0,1.0,1.0,1.0,1.0])         |\n",
      "|[assorted, colour, bird, ornament]        |(262144,[100503,208090,209126,249670],[1.0,1.0,1.0,1.0])                   |\n",
      "|[poppy's, playhouse, bedroom]             |(262144,[34239,122609,207779],[1.0,1.0,1.0])                               |\n",
      "|[poppy's, playhouse, kitchen]             |(262144,[34239,94853,122609],[1.0,1.0,1.0])                                |\n",
      "|[feltcraft, princess, charlotte, doll]    |(262144,[64355,123133,189712,231118],[1.0,1.0,1.0,1.0])                    |\n",
      "|[ivory, knitted, mug, cosy]               |(262144,[5105,122426,149851,203010],[1.0,1.0,1.0,1.0])                     |\n",
      "|[box, of, 6, assorted, colour, teaspoons] |(262144,[9639,18659,107656,189792,208090,249670],[1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|[box, of, vintage, jigsaw, blocks]        |(262144,[9639,87306,88422,189792,250972],[1.0,1.0,1.0,1.0,1.0])            |\n",
      "|[box, of, vintage, alphabet, blocks]      |(262144,[9639,88422,117031,189792,250972],[1.0,1.0,1.0,1.0,1.0])           |\n",
      "|[home, building, block, word]             |(262144,[17893,24031,90428,128327],[1.0,1.0,1.0,1.0])                      |\n",
      "|[love, building, block, word]             |(262144,[24031,90428,128327,186480],[1.0,1.0,1.0,1.0])                     |\n",
      "|[recipe, box, with, metal, heart]         |(262144,[68281,102296,108955,126466,189792],[1.0,1.0,1.0,1.0,1.0])         |\n",
      "+------------------------------------------+---------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfDF.select('tokens','features').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer, Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceData = spark.createDataFrame([\n",
    "    (0.0, \"Hi I heard about Spark\"),\n",
    "    (0.0, \"I wish Java could use case classes\"),\n",
    "    (1.0, \"Logistic regression models are neat\")\n",
    "], [\"label\", \"sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = Tokenizer(inputCol='sentence',outputCol='tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tkData = tk.transform(sentenceData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|            sentence|              tokens|\n",
      "+-----+--------------------+--------------------+\n",
      "|  0.0|Hi I heard about ...|[hi, i, heard, ab...|\n",
      "|  0.0|I wish Java could...|[i, wish, java, c...|\n",
      "|  1.0|Logistic regressi...|[logistic, regres...|\n",
      "+-----+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tkData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(inputCol='tokens',outputCol='feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvModel = cv.fit(tkData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvDF = cvModel.transform(tkData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------------------------+------------------------------------------+\n",
      "|label|sentence                           |tokens                                    |\n",
      "+-----+-----------------------------------+------------------------------------------+\n",
      "|0.0  |Hi I heard about Spark             |[hi, i, heard, about, spark]              |\n",
      "|0.0  |I wish Java could use case classes |[i, wish, java, could, use, case, classes]|\n",
      "|1.0  |Logistic regression models are neat|[logistic, regression, models, are, neat] |\n",
      "+-----+-----------------------------------+------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tkData.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'logistic', 'case', 'heard', 'classes', 'hi', 'regression', 'could', 'are', 'spark', 'about', 'neat', 'java', 'models', 'wish', 'use']\n"
     ]
    }
   ],
   "source": [
    "print(cvModel.vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+------------------------------------------------------+\n",
      "|tokens                                    |feature                                               |\n",
      "+------------------------------------------+------------------------------------------------------+\n",
      "|[white, hanging, heart, t-light, holder]  |(1554,[5,10,17,22,28],[1.0,1.0,1.0,1.0,1.0])          |\n",
      "|[white, metal, lantern]                   |(1554,[10,19,204],[1.0,1.0,1.0])                      |\n",
      "|[cream, cupid, hearts, coat, hanger]      |(1554,[56,96,140,176,373],[1.0,1.0,1.0,1.0,1.0])      |\n",
      "|[knitted, union, flag, hot, water, bottle]|(1554,[13,14,15,47,127,179],[1.0,1.0,1.0,1.0,1.0,1.0])|\n",
      "|[red, woolly, hottie, white, heart.]      |(1554,[0,10,203,208,212],[1.0,1.0,1.0,1.0,1.0])       |\n",
      "|[set, 7, babushka, nesting, boxes]        |(1554,[1,45,65,230,236],[1.0,1.0,1.0,1.0,1.0])        |\n",
      "|[glass, star, frosted, t-light, holder]   |(1554,[17,22,30,54,371],[1.0,1.0,1.0,1.0,1.0])        |\n",
      "|[hand, warmer, union, jack]               |(1554,[23,24,47,85],[1.0,1.0,1.0,1.0])                |\n",
      "|[hand, warmer, red, polka, dot]           |(1554,[0,23,24,315,336],[1.0,1.0,1.0,1.0,1.0])        |\n",
      "|[assorted, colour, bird, ornament]        |(1554,[46,60,66,287],[1.0,1.0,1.0,1.0])               |\n",
      "|[poppy's, playhouse, bedroom]             |(1554,[153,156,379],[1.0,1.0,1.0])                    |\n",
      "|[poppy's, playhouse, kitchen]             |(1554,[107,153,156],[1.0,1.0,1.0])                    |\n",
      "|[feltcraft, princess, charlotte, doll]    |(1554,[33,108,157,303],[1.0,1.0,1.0,1.0])             |\n",
      "|[ivory, knitted, mug, cosy]               |(1554,[27,77,161,179],[1.0,1.0,1.0,1.0])              |\n",
      "|[box, of, 6, assorted, colour, teaspoons] |(1554,[2,7,34,46,66,786],[1.0,1.0,1.0,1.0,1.0,1.0])   |\n",
      "|[box, of, vintage, jigsaw, blocks]        |(1554,[2,7,8,223,478],[1.0,1.0,1.0,1.0,1.0])          |\n",
      "|[box, of, vintage, alphabet, blocks]      |(1554,[2,7,8,478,517],[1.0,1.0,1.0,1.0,1.0])          |\n",
      "|[home, building, block, word]             |(1554,[89,159,244,247],[1.0,1.0,1.0,1.0])             |\n",
      "|[love, building, block, word]             |(1554,[59,159,244,247],[1.0,1.0,1.0,1.0])             |\n",
      "|[recipe, box, with, metal, heart]         |(1554,[5,7,19,40,195],[1.0,1.0,1.0,1.0,1.0])          |\n",
      "+------------------------------------------+------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cvDF.select('tokens','feature').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceData = spark.createDataFrame([\n",
    "    (0.0, \"Hi I heard about Spark\"),\n",
    "    (0.0, \"I wish,, Java could use case- classes\"),\n",
    "    (1.0, \"Logistic, ,regression ,models are neat\")\n",
    "], [\"label\", \"sentence\"])\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(sentenceData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+\n",
      "|words                                        |\n",
      "+---------------------------------------------+\n",
      "|[hi, i, heard, about, spark]                 |\n",
      "|[i, wish,,, java, could, use, case-, classes]|\n",
      "|[logistic,, ,regression, ,models, are, neat] |\n",
      "+---------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wordsData.select('words').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RegexTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = RegexTokenizer(inputCol='sentence', outputCol='words',pattern='\\\\W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexDF = regex.transform(sentenceData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+\n",
      "|words                                     |\n",
      "+------------------------------------------+\n",
      "|[hi, i, heard, about, spark]              |\n",
      "|[i, wish, java, could, use, case, classes]|\n",
      "|[logistic, regression, models, are, neat] |\n",
      "+------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regexDF.select('words').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = HashingTF(inputCol='features',outputCol='newFeatures', numFeatures=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfDF = tf.transform(regexDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|(20,[0,8,12,17,18...|\n",
      "|(20,[9,15,17],[1....|\n",
      "|(20,[6,7,14,17],[...|\n",
      "|(20,[9,11,12,14,1...|\n",
      "|(20,[2,11,12,16,1...|\n",
      "|(20,[0,3,13,16],[...|\n",
      "|(20,[8,10,12,16,1...|\n",
      "|(20,[3,7,14,17],[...|\n",
      "|(20,[0,3,11,17],[...|\n",
      "|(20,[6,14,15],[1....|\n",
      "|(20,[1,7],[2.2875...|\n",
      "|(20,[1,7],[4.5750...|\n",
      "|(20,[5,6,12,15],[...|\n",
      "|(20,[2,6,9,11],[1...|\n",
      "|(20,[3,4,6,12,14,...|\n",
      "|(20,[0,2,3,10,12]...|\n",
      "|(20,[0,3,10,12],[...|\n",
      "|(20,[5,11,12,19],...|\n",
      "|(20,[0,11,12,19],...|\n",
      "|(20,[0,3,9,10,12]...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idfDF.select('features').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stop/Common Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = StopWordsRemover.loadDefaultStopWords('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = StopWordsRemover(inputCol='words',stopWords=dic,outputCol='removed_words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopedDF = stopwords.transform(regexDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+------------------------------------+\n",
      "|words                                     |removed_words                       |\n",
      "+------------------------------------------+------------------------------------+\n",
      "|[hi, i, heard, about, spark]              |[hi, heard, spark]                  |\n",
      "|[i, wish, java, could, use, case, classes]|[wish, java, use, case, classes]    |\n",
      "|[logistic, regression, models, are, neat] |[logistic, regression, models, neat]|\n",
      "+------------------------------------------+------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stopedDF.select('words','removed_words').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Word Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import NGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng = NGram(inputCol='words',n=2, outputCol='ngrams')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngDF = ng.transform(regexDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               words|              ngrams|\n",
      "+--------------------+--------------------+\n",
      "|[hi, i, heard, ab...|[hi i, i heard, h...|\n",
      "|[i, wish,,, java,...|[i wish,,, wish,,...|\n",
      "|[logistic,, ,regr...|[logistic, ,regre...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ngDF.select('words','ngrams').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Words into Numerical Representations\n",
    "\n",
    "hashingTF, IDF, CountVectorizer, Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "va = VectorAssembler(inputCols=['int1','int2','int3'],outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_intDF = va.transform(intDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+-------------+\n",
      "|int1|int2|int3|     features|\n",
      "+----+----+----+-------------+\n",
      "|   1|   2|   3|[1.0,2.0,3.0]|\n",
      "|   4|   5|   6|[4.0,5.0,6.0]|\n",
      "|   7|   8|   9|[7.0,8.0,9.0]|\n",
      "+----+----+----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "va_intDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.stat import Summarizer\n",
    "\n",
    "summarizer = Summarizer.metrics(\"count\",\"mean\",\"variance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summarizer.summary(va_intDF.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+\n",
      "|aggregate_metrics(features, 1.0) |\n",
      "+---------------------------------+\n",
      "|[3, [4.0,5.0,6.0], [9.0,9.0,9.0]]|\n",
      "+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "va_intDF.select(summary).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
